<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-04-29T11:48:06-04:00</updated><id>http://localhost:4000/</id><title type="html">Software Architecture Blog</title><subtitle>Pontifications on all things architecture within the context of Enterprise IT. Thoughs from Chief Architect who spends his time with many of Red Hat's customers in the Northeast USA.</subtitle><entry><title type="html">Microservices are great for all-the-things but what about the data</title><link href="http://localhost:4000/jekyll/update/2018/03/23/DataManagementStrategies.html" rel="alternate" type="text/html" title="Microservices are great for all-the-things but what about the data" /><published>2018-03-23T12:16:01-04:00</published><updated>2018-03-23T12:16:01-04:00</updated><id>http://localhost:4000/jekyll/update/2018/03/23/DataManagementStrategies</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/03/23/DataManagementStrategies.html">&lt;p&gt;If you’ve been following the trends around modern application development, you’ve likely been inundated with reasons why you need to adopt microservices. You know about domain-driven design, the perks of 2-pizza teams, and you’re familiar with consumer-driven contracts. What’s not discussed as often is how to best manage application state and user data within a scaled microservice architecture.&lt;/p&gt;

&lt;p&gt;In part one of a two-part series, I’m going explore some of the historical challenges and define several approaches for a more thoughtful distributed data architecture.&lt;/p&gt;

&lt;p&gt;Let’s take a moment to reflect on how sophisticated and robust modern software has become. Big steps have been made in tooling for code craftsmanship, quality analysis, and automated tests. We now have the ability to use machine intelligence to improve code performance and rectify security vulnerabilities before a production go-live! Data access is easier thanks to today’s frameworks, libraries, and integrated runtimes, which also allow just-in-time data model creation with full create-read-update-delete semantics.&lt;/p&gt;

&lt;p&gt;Writing high-quality functioning code is easier today than ever before; what’s hard is managing the state of the application. For example, in a distributed architecture, how do we ensure consistency of user experience, data reporting, data analytics? How do we ensure transaction consistency, write and read performance under load, etc.? And how do we do it all within an ephemeral cloud-based infrastructure?&lt;/p&gt;

&lt;h3 id=&quot;the-red-headed-stepchild&quot;&gt;The red headed stepchild&lt;/h3&gt;

&lt;p&gt;In traditional java-based development, data can easily become the red-headed stepchild. That’s because traditional Java-based development has you model your domain objects into POJOs (plain-old-Java-object) which are then mapped to an underlying data schema; typically your data access layer. The data schema is created and maintained via ORM (object-relational-mapping) tools. This programing model makes it easy to build the data access layer, however the resulting data model and physical schema is often anemic and not representative of the overall enterprise data architecture.&lt;/p&gt;

&lt;p&gt;Writing software in this manner places the application as the source of essential complexity, resulting in accidental complexity of the associated data model, a common side effect of software development. Moreover, software development heavily influences physical data structure, storage requirements, consistency rules, access patterns etc — and it’s all done accidentally, hence data becoming the red-headed stepchild.&lt;/p&gt;

&lt;h3 id=&quot;the-impedance-problem&quot;&gt;The impedance problem&lt;/h3&gt;

&lt;p&gt;More recent application development approaches focus on modeling the business domain into business-specific functionality aka “rules of the business.” Development using this rules-first approach is commonly defined as domain driven design (DDD). First documented by Eric Evans, DDD is a mature approach for defining and architecting systems around like business concepts (bounded contexts) and requires a strong collaboration between engineering and business owners. However, when it comes to modeling the supporting data architecture, we still rely on ORM mapping techniques with little to no improvement over creating a POJO architecture.&lt;/p&gt;

&lt;p&gt;When you consider the change friction at the schema level versus the change friction at the application level, it’s easy to rationalize that all changes directly to the data schema are painful. On the other hand, when you properly abstract the schema from the application (e.g. data interface), then friction becomes close to non existent; schema modifications are painful whereas application changes are much easier.&lt;/p&gt;

&lt;h3 id=&quot;microservices-solve-all-the-things&quot;&gt;Microservices solve all-the-things&lt;/h3&gt;

&lt;p&gt;When we apply sound DDD principles to a distributed service-based architecture we are immediately confronted with the data problem. Microservice purists espouse the need to manage data as part of the overall service lifecycle and often times this translates into  creating and managing copies of data. If we consider that each bounded context has its own data model, we move into this uneasy place of forced data duplication.&lt;/p&gt;

&lt;p&gt;What happens when the teams pick differing persistent stores? Combinations of relational databases? NoSQL structures? And distributed caches? This lack of data strategy fosters database sprawl, increased cost, needless operational overhead and data consistency issues. Data purists shrill at this approach and have worked to define other techniques and architectures that not only support a microservice architecture but are also better custodians of enterprise data management.&lt;/p&gt;

&lt;h3 id=&quot;a-few-approaches&quot;&gt;A few approaches&lt;/h3&gt;

&lt;p&gt;One strategy that can significantly help the database-per-microservice dogma is to architect with data virtualization. Data virtualization can provide an in-memory bounded context-specific data model per microservice as an abstraction above the physical data schema. With data virtualization, data is never isolated, never replicated to physical data schemas, and correlations across data sources are permitted. Virtual databases provide data agility, fit-for-purpose data models, and fit-for-service data security (e.g. RBAC, attribute masking, etc. … ).&lt;/p&gt;

&lt;p&gt;Another data strategy for microservices is to leverage in-memory distributed caching architectures. Adding caching strategies such as replication and partitioning directly to the cache instance can assist the architecture depending on use case. Replication is concerned with sharing memory across nodes to allow for storing critical data such as user session data. This session data needs to be consistent across nodes, durable for fault tolerance and elastically scalable. Whereas partitioning allows for co-locating data alongside the actual microservice in a ‘sidecar’ approach. Partitioning supports data sharding at a per-service level providing greater security than straight replication and it also supports a near/far cache architecture with a remote distributed data grid.&lt;/p&gt;

&lt;p&gt;Given the two approaches outlined, we have yet to consider several core data management concerns including data consistency and a core fallacy of distributed computing. Recall Eric Brewer’s CAP theorem which states that given a network partition (distributed computing fallacy #1 is the network is reliable) you need to choose between consistency or availability. When solving for consistency, change data capture (CDC) strategies can be your friend. A refinement to CDC is with the addition of event sourcing and state change propagation which provides the feel of a highly-consistent data architecture while allowing for asynchronous performance and elasticity benefits.&lt;/p&gt;

&lt;h3 id=&quot;everything-is-an-event&quot;&gt;Everything is an event&lt;/h3&gt;

&lt;p&gt;An architectural approach that can solve many of the data problems inherent with a distributed architecture is event sourcing. Event sourcing, as defined by Martin Fowler, is a process by which you “capture all changes to an application state as a sequence of events.” In the data context, microservices publish and subscribe to data events and persist state change to a replayable append-only log. Event sourcing provides eventual consistency of data across the network and also eliminates the need for data management within the lifecycle of the microservice. Streaming technologies such as Apache Kafka are often used to manage the event messaging fabric and have been designed to excel in distributed environments where eventual consistency and asynchronous communication are defaults.&lt;/p&gt;

&lt;p&gt;In order to evolve into a fully distributed architecture that exploits microservices, we need to consider the impact on data and not treat it as accidental complexity. Microservice development using traditional object mapping tools that build bespoke data snowflakes do not take into account data replication, consistency, and the larger problem of enterprise data management. When working to ensure the health of data within a microservices architecture, there are a number of classic approaches that can work including data virtualization and caching. Taking the architecture one step further, we can all but reduce the need for data gravity at the microservice and only concern ourselves with data in motion by building reactive event driven services that operate on streams of data. More to come on this topic in part two.&lt;/p&gt;</content><author><name></name></author><summary type="html">If you’ve been following the trends around modern application development, you’ve likely been inundated with reasons why you need to adopt microservices. You know about domain-driven design, the perks of 2-pizza teams, and you’re familiar with consumer-driven contracts. What’s not discussed as often is how to best manage application state and user data within a scaled microservice architecture.</summary></entry><entry><title type="html">Modern Application Development: Should you skip microservices and go directly to serverless?</title><link href="http://localhost:4000/jekyll/update/2018/01/19/Modern_App_Dev.html" rel="alternate" type="text/html" title="Modern Application Development: Should you skip microservices and go directly to serverless?" /><published>2018-01-19T11:16:01-05:00</published><updated>2018-01-19T11:16:01-05:00</updated><id>http://localhost:4000/jekyll/update/2018/01/19/Modern_App_Dev</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/01/19/Modern_App_Dev.html">&lt;p&gt;You don’t have to look further than the Gartner Hype Cycle to see the staggering pace of innovation in application architecture. Microservices, reactive programming, and container management are among the architectural models at the peak of the Cycle, making deep scrutiny a must as you consider the systems, processes, and tool choices for modern application development. And while it’s not entirely unheard of to skip a generation of technology and jump headfirst into the latest shiny object, doing so often comes with significant risk. It’s not quite the same as a strong advancement in the game of Monopoly. So if you’re wondering if you should skip microservices and go directly to serverless, here’s some food for thought.
Recently,function-as-as-service (FaaS) and serverless technologies like AWS Lambda have captured our imaginations with the promise to run idempotent units of functionality at scale on someone else’s infrastructure. In some ways, it represents one of the largest technology unicorns in the land.&lt;/p&gt;

&lt;p&gt;It’s not all rainbows and butterflies
Serverless architectures leverage the elastic compute capacity of an underlying infrastructure to provide ephemeral and idempotent functions (e.g. file handling, data transformation, system integration, single-sign-on, etc.) that can be invoked directly by business applications. These services/functions are considered an easy method to implement ‘pay-as-you-go’ event-driven, stateless microservices. Further, serverless architectures promote the ability to reduce many core IT responsibilities such as patching and maintaining servers, networking, scaling of services, etc. Problems can arise however, when trying to understand the appropriate service to use for a given problem; architectural governance and standards are now more dependant on partner relationships and not in the firm control of the service consumer or enterprise IT.&lt;/p&gt;

&lt;p&gt;A quick history lesson
Serverless and FaaS has its foundation in functional programming. Recall, functional programming originates from concepts developed in the 1930s with Lambda Calculus. It’s rooted in function definition, function abstraction and the usage of variables for function application. We didn’t see much from functional programming until the 1960s, when Common Lisp became the first functional programming language. Since then, functional programming evolved and many popular languages of today have support for functional programming concepts including JavaScript, Python, C# and even Java.
When considering the idempotent and stateless nature of functions, you can see why functional programming has strong relevance to microservice-based cloud-native application development. Taking it a step further, a cloud-native application can easily leverage a function call to a FaaS or serverless environment to perform a number of activities, such as processing a customer login event, computing an analytic, or evaluating a decision. And it can do it all while never having to be concerned with the underlying function scale, security, maintenance or performance (kinda cool). Having said that, there is some level of lock-in with Google Cloud functions, Microsoft Azure Functions, Amazon Lambda, Oracle Functions, VMWare Functions, etc. due to their pervasive coupling on underlying and supporting dependant services. This coupling and chaining of services at scale must be considered as part of an enterprise serverless strategy and governance model to ensure application portability and overall cost of ownership.&lt;/p&gt;

&lt;p&gt;The hidden costs of serverless architectures
While many of the core technologies and architecture styles that support cloud-native development are readily available today, adopting them wholesale may come with a significant cost. Serverless architectures come with hard and soft costs that may not be immediately obvious. Hard costs may include added network latency and difficulty in troubleshooting a business transaction through a distributed service mesh. Soft costs include the technical team competency needed for managing high levels of complexity, as well as the overall application and service portability (cost of migration from one serverless platform/vendor to another).&lt;/p&gt;

&lt;p&gt;Providing guardrails, not gates
Red Hat understands the serverless and FaaS landscape as a forest of promise not without its hidden monsters. That said, we are working with communities to implement new technologies that provide guardrails and not gates. We want enterprise development teams to have the freedom to innovate at full speed but without compromising on built-in, enterprise-required controls such as security, stability and governance. An example of this approach is with Red Hat OpenShift Application Runtimes (RHOAR), which is a collection of application development runtimes and languages that support cloud-native, microservice-based development and includes a path to serverless architectures. RHOAR, along with the OpenShift Container Management Platform, will in time include core technologies that enable serverless architectures for private, hybrid and multi-cloud deployments. Leveraging the Red Hat approach to serverless architectures allows an enterprise to fully own, manage and govern their services at scale and across cloud providers to quickly build, run and maintain cloud-native applications.&lt;/p&gt;

&lt;p&gt;While skipping an evolution to microservices and jumping right to the unicorn-serverless-world may sound appealing, the approach doesn’t come without significant risk. As with all evolution, incremental steps of improvement that are well understood and illustrate environmental adaptations are the most successful and sustainable. That said, moving from big monoliths to fast-moving monoliths, from microservices to serverless is, perhaps, the most successful approach that enterprise IT teams should adopt. It’s a better than keeping your fingers crossed that you’ll roll the dice, pass GO and collect $200.&lt;/p&gt;</content><author><name></name></author><summary type="html">You don’t have to look further than the Gartner Hype Cycle to see the staggering pace of innovation in application architecture. Microservices, reactive programming, and container management are among the architectural models at the peak of the Cycle, making deep scrutiny a must as you consider the systems, processes, and tool choices for modern application development. And while it’s not entirely unheard of to skip a generation of technology and jump headfirst into the latest shiny object, doing so often comes with significant risk. It’s not quite the same as a strong advancement in the game of Monopoly. So if you’re wondering if you should skip microservices and go directly to serverless, here’s some food for thought. Recently,function-as-as-service (FaaS) and serverless technologies like AWS Lambda have captured our imaginations with the promise to run idempotent units of functionality at scale on someone else’s infrastructure. In some ways, it represents one of the largest technology unicorns in the land.</summary></entry></feed>